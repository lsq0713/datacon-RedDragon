{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 黄牛检测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "file_path = './data/raw_data.xlsx'\n",
    "sheet_name = 'Sheet1'\n",
    "data = pd.read_excel(file_path, sheet_name=sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间预处理\n",
    "data['订单创建时间'] = pd.to_datetime(data['订单创建时间'])\n",
    "data['就诊日期'] = pd.to_datetime(data['就诊日期'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', '省份', 'APPID', 'IP_ADDRESS', '订单创建时间', '患者ID', '患者创建时间', '就诊日期',\n",
      "       '就诊科室名称', '医生姓名', '状态', '商户订单号'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 基于规则的检测\n",
    "\n",
    "1. IP重复，来自同一个IP，且为超过3个人挂号\n",
    "2. 用户重复，来自同一个用户，且挂号了超过3个科室/超过两个app_id\n",
    "3. 时间过早，每天5:00-5:01进行操作的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重复值筛选，找出data的seg_name字段中重复数大于limit的行, sort_add和asc_add是检测完之后添加的排序要求\n",
    "def duplicate_detect(data, seg_name, limit, up=True, sort_add=[], asc_add=[]):\n",
    "    assert len(sort_add) == len(asc_add)\n",
    "    value_counts = data[seg_name].value_counts()\n",
    "    if up:\n",
    "        # 向上筛\n",
    "        dup_row = data[data[seg_name].isin(value_counts[value_counts > limit].index)]\n",
    "    else:\n",
    "        # 向下筛\n",
    "        dup_row = data[data[seg_name].isin(value_counts[value_counts < limit].index)]\n",
    "    sort_by = [seg_name] + sort_add\n",
    "    asc = [True] + asc_add\n",
    "    dup_row = dup_row.sort_values(by=sort_by, ascending=asc)\n",
    "    return dup_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选出同一个dup_seg中有超过limit个unique_seg的索引(从0开始)\n",
    "def unique_dup_filter(data, dup_seg, unique_seg, limit, up=True, get_row=False):\n",
    "    # 确定是黄牛的行编号\n",
    "    selects = []\n",
    "    # IP重复检测\n",
    "    dup = duplicate_detect(data, dup_seg, limit, up=up, sort_add=[unique_seg], asc_add=[True])\n",
    "    print(\"init dup_num:\", len(dup))\n",
    "    if len(dup) == 0:\n",
    "        return selects\n",
    "    pos = 0          # 这个IP的起点\n",
    "    count = 1      # 涉及多少个用户ID\n",
    "    last = dup[unique_seg].iloc[0] # 上一个用户的ID\n",
    "    dup_num = len(dup)\n",
    "    for i in tqdm(range(1, dup_num)):\n",
    "        if dup[dup_seg].iloc[i] == dup[dup_seg].iloc[pos]:\n",
    "            if dup[unique_seg].iloc[i] != last:\n",
    "                # 相同IP下一个新的患者\n",
    "                count += 1\n",
    "                last = dup[unique_seg].iloc[i]\n",
    "        if dup[dup_seg].iloc[i] != dup[dup_seg].iloc[pos] or i == dup_num - 1:\n",
    "            # 开始检测下一个IP\n",
    "            if count > limit:\n",
    "                # 达到重复人数条件\n",
    "                for j in range(pos, i):\n",
    "                    selects.append(dup['ID'].iloc[j])\n",
    "            # 重置\n",
    "            pos = i\n",
    "            count = 1\n",
    "            last = dup[unique_seg].iloc[i]\n",
    "    print(\"filtered dup_num:\", len(selects))\n",
    "    if not get_row:\n",
    "        selects.sort()\n",
    "        return selects\n",
    "    else:\n",
    "        dup_rows = data[data['ID'].isin(selects)]\n",
    "        dup_rows = dup_rows.sort_values(by=dup_seg, ascending=True)\n",
    "        return dup_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对unique_dup_filter, 在一定范围内遍历limit\n",
    "# 使用: limits, select_list = grid_traverse(data, '患者ID', '就诊科室名称', 5, 10)\n",
    "def grid_traverse(data, dup_seg, unique_seg, start, end, gap=1):\n",
    "    limits = []\n",
    "    selects_list = []\n",
    "    for limit in range(start, end, gap):\n",
    "        print(f\"limit: {limit}\")\n",
    "        selects = unique_dup_filter(data, dup_seg, unique_seg, limit)\n",
    "        limits.append(limit)\n",
    "        selects_list.append(selects)\n",
    "    return limits, selects_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将一个list写作答案\n",
    "def write_list(lis):\n",
    "    # 打开一个文件进行写入，如果文件不存在则创建\n",
    "    with open('./data/result.txt', 'w', encoding='utf-8') as file:\n",
    "        # 遍历列表中的每个元素\n",
    "        for item in lis:\n",
    "            # 将每个元素写入文件，每个元素后面加上换行符\n",
    "            file.write(str(item) + '\\n')\n",
    "        print(f\"Total line: {len(lis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间段过滤器，过滤出每天一段时间内的数据\n",
    "# 形如daily_filter(data, '5:00:00', '5:01:00')\n",
    "def daily_filter(data, start, end):\n",
    "    return data[(data['订单创建时间'].dt.time >= pd.to_datetime(start).time()) &\n",
    "                    (data['订单创建时间'].dt.time <= pd.to_datetime(end).time())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 时间分段统计\n",
    "def hour_count():\n",
    "    print(\"\\t\\t总数\\t已挂号  医保换号  已退号  窗口退号  无号退款  超时取消\")\n",
    "    for i in range(5, 23):\n",
    "        time_filter = data[(data['订单创建时间'].dt.time >= pd.to_datetime(f'{i}:00:00').time()) &\n",
    "                     (data['订单创建时间'].dt.time <= pd.to_datetime(f'{i+1}:00:00').time())]\n",
    "        counts = time_filter['状态'].value_counts()\n",
    "        print(f\"{i}:00 - {i+1}:00 \\t{len(time_filter)}\\t{counts['已挂号']}\\t{counts['医保换号']}\\t {counts['已退号']}\\t\"\n",
    "              f\"   {counts['窗口退号']}\\t   {counts['无号退款']}\\t    {counts['超时取消']}\\t\")\n",
    "\n",
    "def minute_line(data, hour):\n",
    "    count = []\n",
    "    for i in tqdm(range(0, 59, 5)):\n",
    "        start = str(i)\n",
    "        end = str(i+5)\n",
    "        if len(start) < 2:\n",
    "            start = '0' + start\n",
    "        if len(end) < 2:\n",
    "            end = '0' + end \n",
    "        time_filter = data[(data['订单创建时间'].dt.time >= pd.to_datetime(f'{hour}:{start}:00').time()) &\n",
    "                     (data['订单创建时间'].dt.time <= pd.to_datetime(f'{hour}:{end}:00').time())]\n",
    "        count.append(len(time_filter))\n",
    "    plt.plot(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 恰好在16:00进行第二天/下一周操作\n",
    "def hurry_sixteen(data, get_row=False):\n",
    "    gap = daily_filter(data, '16:00:00', '16:00:01')\n",
    "    time_diff = (gap['就诊日期'] - gap['订单创建时间']).dt.days\n",
    "    hurry_row = gap[(time_diff == 0) | (time_diff == 6)]\n",
    "    if get_row:\n",
    "        return hurry_row\n",
    "    else:\n",
    "        return hurry_row['ID'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将之前一次答案中的数据提取成列表\n",
    "def get_list(res_id):\n",
    "    file_path = f'./data/result{res_id}.txt'\n",
    "    with open(file_path, 'r') as file:\n",
    "        lis = [int(line.strip()) for line in file]\n",
    "    return lis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两个list进行对比\n",
    "def lis_cmp(lis1, lis2, ret=False):\n",
    "    set1 = set(lis1)\n",
    "    set2 = set(lis2)\n",
    "    new_ele = set2 - set1\n",
    "    miss_ele = set1 - set2\n",
    "    same_ele = set1.intersection(set2)\n",
    "    print(f\"lis1: {len(lis1)}, lis2: {len(lis2)}, more: {len(new_ele)}, miss: {len(miss_ele)}, same = {len(same_ele)}\")\n",
    "    if ret:\n",
    "        return new_ele, miss_ele\n",
    "\n",
    "# 与之前一次答案进行对比\n",
    "def res_cmp(res_id, lis, ret=False):\n",
    "    lis1 = get_list(res_id)\n",
    "    res = lis_cmp(lis1, lis)\n",
    "    if ret:\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 频繁退号\n",
    "def frequent_drop(data, limit, get_row=False):\n",
    "    drop = data[data['状态'] == '已退号']\n",
    "    mass_drop = duplicate_detect(drop, \"患者ID\", limit)\n",
    "    if get_row:\n",
    "        return mass_drop['ID'].tolist()\n",
    "    else:\n",
    "        return mass_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确认不是黄牛(要小心让模型学到的是什么，有些东西可以拿来筛选但是不能输给模型，可能设置不超过)\n",
    "# 条件：\n",
    "# 1. IP行\n",
    "# 2. 用户挂号3次及以下，且是相同的科室和相同APPID\n",
    "# 3. 北京/河北\n",
    "# 4. 时间不在两个重点时段5:00 - 6:00, 16:00 - 16:30\n",
    "def normal_people(data):\n",
    "    ip_limit = duplicate_detect(data, 'IP_ADDRESS', 2, up=False)\n",
    "    print(f\"limit: {len(ip_limit)}\")\n",
    "    user_limit = duplicate_detect(ip_limit, '患者ID', 4, up=False)\n",
    "    print(f\"limit: {len(user_limit)}\")\n",
    "    depart_limit = duplicate_detect(user_limit, '就诊科室名称', 10, up=False)\n",
    "    print(f\"limit: {len(depart_limit)}\")\n",
    "    app_limit = duplicate_detect(depart_limit, 'APPID', 2, up=False)\n",
    "    print(f\"limit: {len(app_limit)}\")\n",
    "    area_limit = app_limit[(app_limit['省份'] == '北京') | (app_limit['省份'] == '河北')]\n",
    "    print(len(area_limit))\n",
    "    # time_limit = area_limit[((area_limit['订单创建时间'].dt.time >= pd.to_datetime(f'6:00:00').time()) &\n",
    "    #                  (area_limit['订单创建时间'].dt.time <= pd.to_datetime(f'16:00:00').time())) | \n",
    "    #                  area_limit['订单创建时间'].dt.time >= pd.to_datetime(f'17:00:00').time()]\n",
    "    time_limit = area_limit[((area_limit['订单创建时间'].dt.time >= pd.to_datetime(f'6:00:00').time()) &\n",
    "                     (area_limit['订单创建时间'].dt.time <= pd.to_datetime(f'16:00:00').time()))]\n",
    "    return time_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据权重在多个不同的list中进行合并筛选\n",
    "def weighted_selection(lists, weights, n, limit=0):\n",
    "    # 创建一个字典来存储元素的总权重\n",
    "    total_weights = defaultdict(float)\n",
    "\n",
    "    # 遍历每个列表及其对应的权重\n",
    "    for lst, weight in zip(lists, weights):\n",
    "        for element in lst:\n",
    "            total_weights[element] += weight  # 累加权重\n",
    "\n",
    "    # 将字典转换为列表，并筛选出权重大于 limit 的元素\n",
    "    filtered_elements = {k: v for k, v in total_weights.items() if v >= limit}\n",
    "\n",
    "    # 按照权重排序\n",
    "    sorted_elements = sorted(filtered_elements.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 选择前 n 个元素及其权重\n",
    "    top_n_elements = sorted_elements[:n]\n",
    "\n",
    "    return top_n_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 工作区"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init dup_num: 46607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46606/46606 [00:01<00:00, 23703.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered dup_num: 45544\n",
      "init dup_num: 14443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14442/14442 [00:00<00:00, 28059.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered dup_num: 4999\n",
      "init dup_num: 61175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61174/61174 [00:01<00:00, 32617.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered dup_num: 595\n",
      "Total line: 8921\n"
     ]
    }
   ],
   "source": [
    "# 第四次测试(11.15)\n",
    "IP_USER = 50\n",
    "USER_DORM = 6\n",
    "AREA_COUNT = 40\n",
    "USER_APPID = 3\n",
    "DROP_LIMIT = 8\n",
    "# IP相同，用户数超过IP_USER，且属地不在北京/河北\n",
    "ip_dup_rows = unique_dup_filter(data, 'IP_ADDRESS', '患者ID', IP_USER, get_row=True)\n",
    "area_limit_rows = ip_dup_rows[(ip_dup_rows['省份'] != '北京') & (ip_dup_rows['省份'] != '河北')]\n",
    "select1 = area_limit_rows['ID'].tolist()\n",
    "# 用户相同，在超过USER_DORM个科室挂号\n",
    "select2 = unique_dup_filter(data, '患者ID', '就诊科室名称', USER_DORM)\n",
    "# 在5:00:00-5:00:01之间挂号\n",
    "select3 = daily_filter(data, '5:00:00', '5:00:01')['ID'].tolist()\n",
    "# 在16:00:00-16:00:01之间挂号(挂号第二天/下一周当天)\n",
    "select4 = hurry_sixteen(data)\n",
    "# 低频地区(少于AREA_COUNT次操作)\n",
    "area_limit = duplicate_detect(data, '省份', AREA_COUNT, False)\n",
    "select5 = area_limit['ID'].tolist()\n",
    "# 同一用户使用超过USER_APPID个APPID操作\n",
    "select6 = unique_dup_filter(data, '患者ID', 'APPID', USER_APPID)\n",
    "# 同一用户超过DROP_LIMIT次退号\n",
    "select7 = frequent_drop(data, DROP_LIMIT)['ID'].tolist()\n",
    "select = select1 + select2 + select3 + select4 + select5 + select6 + select7\n",
    "select = list(set(select))\n",
    "select.sort()\n",
    "write_list(select)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total line: 5824\n"
     ]
    }
   ],
   "source": [
    "selects = [select1, select2, select3, select4, select5, select6, select7]\n",
    "weights = [0.7, 0.5, 0.8, 0.3, 0.8, 0.6, 0.7]\n",
    "# 总得分超过LIMIT,且在前N个\n",
    "LIMIT = 0.5\n",
    "N = 6500\n",
    "res = weighted_selection(selects, weights, N, limit=LIMIT)\n",
    "res = [pair[0] for pair in res]\n",
    "res.sort()\n",
    "write_list(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lis1: 6339, lis2: 8921, more: 2582, miss: 0, same = 6339\n",
      "lis1: 8480, lis2: 8921, more: 441, miss: 0, same = 8480\n"
     ]
    }
   ],
   "source": [
    "res_cmp(1, select)\n",
    "res_cmp(2, select)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
